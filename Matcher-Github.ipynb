{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Scrape a complete part list###\n",
    "\n",
    "#Get content and find all a[href]\n",
    "def getHref(url):\n",
    "    soupOverview = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "    urls = soupOverview.select('#content_block')[0].findAll('a', href=True)\n",
    "    return urls\n",
    "\n",
    "#Settings\n",
    "tisUrlOverview = \"\"\n",
    "filename = tisUrlOverview.split(\"parts-catalog/\")[1].split(\"/browse\")[0].replace('/', \"_\").replace('.', \"\").replace('-', \"_\")\n",
    "baseUrl = \"\"\n",
    "\n",
    "#Get all 1st level category URLs and parse them to object\n",
    "categories = []\n",
    "for e in getHref(tisUrlOverview):\n",
    "    if \"browse\" in e['href']: \n",
    "        categories.append({\n",
    "            \"title\" : e.text.strip(),\n",
    "            \"url\" : baseUrl+e['href'],\n",
    "            \"subcategories\" : [], \n",
    "        })\n",
    "print(len(categories), \"categories fetched!\")\n",
    "\n",
    "#Get all subcategories URLs\n",
    "scCounter = 0\n",
    "for i in range(0, len(categories)):\n",
    "    for e in getHref(categories[i].get('url')):\n",
    "        if \"browse\" in e['href']: \n",
    "            categories[i][\"subcategories\"].append({\n",
    "                \"title\" : e.text.strip(),\n",
    "                \"url\" : baseUrl+e['href'], \n",
    "                \"parts\" : [],     \n",
    "            })\n",
    "            scCounter += 1\n",
    "print(str(scCounter), \"subcategories fetched!\")\n",
    "\n",
    "#For all Categories\n",
    "parts = []\n",
    "part = {}\n",
    "partVariation = \"\"\n",
    "for i in range(0, len(categories)):\n",
    "    for z in range(0, len(categories[i].get('subcategories'))-1):\n",
    "        url = categories[i].get('subcategories')[z].get('url')\n",
    "        partsTable = BeautifulSoup(requests.get(url).text, 'html.parser').select('#parts_table')[0].find('tbody')\n",
    "    \n",
    "        #Parse parts page\n",
    "        part = {}\n",
    "        partVariation = \"\"\n",
    "        for e in partsTable.findAll('tr', recursive=False)[0:]:\n",
    "\n",
    "            #Get name of the part from \"title_row\" \n",
    "            if e.select('.title_row') and len(e.select('.small_text')[0].text) > 0:\n",
    "                partName = e.select('.small_text')[0].text\n",
    "                if len(e.select('.small_text')) > 1:\n",
    "                    partVariation = e.select('.small_text')[1].text \n",
    "\n",
    "            #Get other Columns\n",
    "            if (not e.select('.title_row') and len(e.text.strip())>0 and e.get(\"id\") != \"accent_tr\"):\n",
    "                part = {}\n",
    "                part[\"name\"] = partName \n",
    "                part[\"id\"] = e.select('.clipboard_part')[0].get('value')\n",
    "                part[\"note\"] = e.select('.clipboard_part')[0].findNext('td', {\"class\": \"part_td\"}).text.strip().replace('\\n', ' ')\n",
    "                if len(e.select(\".add_td\"))> 0 and 'Für Fahrzeuge mit' in e.select(\".add_td\")[0].text:\n",
    "                    partVariation = e.select(\".add_td\")[0].select(\"div.mobile.only\")[0].select(\"div.drop_info.hide\")[0].text\n",
    "\n",
    "                if len(partVariation) > 0 and 'Für Fahrzeuge mit' in partVariation:\n",
    "                    part[\"variation\"] = re.split('Für Fahrzeuge mit', partVariation)[1].replace('\\n','').replace('', '').replace(\"Ja\", \"Ja \").replace(\"Nein\", \"Nein \")\n",
    "                else:\n",
    "                    part[\"variation\"] = \"\"\n",
    "                part[\"amount\"] = e.select(\"td.light.part_td.small.center_text\")[0].text.strip().replace('\\n', ' ')    \n",
    "                part[\"category\"] = categories[i].get('title')\n",
    "                part[\"categoryURL\"] = categories[i].get('url')\n",
    "                part[\"subcategory\"] = categories[i].get('subcategories')[z].get('title')\n",
    "                part[\"subcategoryURL\"] = categories[i].get('subcategories')[z].get('url')\n",
    "                parts.append(part)\n",
    "\n",
    "            #Reset new Part\n",
    "            if (e.get(\"id\") == \"accent_tr\"):\n",
    "                partVariation = \"\"\n",
    "                partName = \"\"\n",
    "        print(categories[i].get('subcategories')[z].get('title'), \"succesfull crawled\")\n",
    "    print(categories[i].get('title'), \"succesfull crawled\")\n",
    "    \n",
    "#Export to DataFrame\n",
    "data = json.dumps(parts)\n",
    "json_data = json.loads(data)\n",
    "df = json_normalize(json_data)\n",
    "df.to_csv(filename + '.csv', index = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "cat_compare = \"Bremsen\"\n",
    "#subcat_compare = \"Hinterradbremse-Bremsscheibe\"\n",
    "\n",
    "#Chose Cars and Read Files\n",
    "df_c_initial = pd.read_csv('E85_25_M54.csv')\n",
    "df_c_compare = pd.read_csv('E85_30_M54.csv')\n",
    "\n",
    "#Chose Category to Compare and Trim DF\n",
    "df_c_initial = df_c_initial[df_c_initial.category == cat_compare]\n",
    "df_c_compare = df_c_compare[df_c_compare.category == cat_compare]\n",
    "\n",
    "#Chose Subcategory to Compare and Trim DF\n",
    "if subcat_compare:\n",
    "    df_c_initial = df_c_initial[df_c_initial.subcategory == subcat_compare]\n",
    "    df_c_compare = df_c_compare[df_c_compare.subcategory == subcat_compare]\n",
    "\n",
    "#Compare Both DF\n",
    "df_compared = pd.DataFrame()\n",
    "for tn in df_c_compare.id:\n",
    "    if len(df_c_initial[df_c_initial.id == tn]) == 0:\n",
    "        df_compared = df_compared.append(df_c_compare[df_c_compare.id == tn])\n",
    "df_compared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
